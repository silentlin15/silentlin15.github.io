
# üìù Publications
## Selected Papers

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICLR</div><img src='images/megatts.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[MegaTTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis](https://openreview.net/forum?id=mvMI3N4AvD) \\
Ziyue Jiang, **Jinglin Liu**\*, Yi Ren, Jinzheng He, Zhenhui Ye, Shengpeng Ji, Qian Yang, Chen Zhang, Pengfei Wei, Chunfeng Wang, Xiang Yin, Zejun MA, Zhou Zhao; <img src='./images/bytedance_logo.svg' style="width: 4em;"> & ZJU

[**Project**](https://boostprompt.github.io/boostprompt/) 

- **Brief Introduction**: Large Text-to-Speech Model.

</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI</div><img src='images/diffsinger.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism](https://arxiv.org/abs/2105.02446) \\
**Jinglin Liu**, Chengxi Li, Yi Ren, Feiyang Chen, Zhou Zhao

[**Project**](https://diffsinger.github.io/) \| [![](https://img.shields.io/github/stars/MoonInTheRiver/DiffSinger?style=social&label=DiffSinger-Stars)](https://github.com/MoonInTheRiver/DiffSinger) \| [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=SpeechDemo)](https://huggingface.co/spaces/NATSpeech/DiffSpeech) \| [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=SingingDemo)](https://huggingface.co/spaces/Silentlin/DiffSinger)


- **Brief Introduction**: This paper contains the first acoustic models based on diffusion, including DiffSinger (SVS) and DiffSpeech (TTS). It realizes the high-quality speech/singing synthesis.
- DiffSinger & DiffSpeech have recieved ![GitHub Stars](https://img.shields.io/github/stars/MoonInTheRiver/DiffSinger?style=social) , and the downloads number of pre-trained model is ![downloads](https://img.shields.io/github/downloads/MoonInTheRiver/DiffSinger/total.svg).
- Many [video demos](https://search.bilibili.com/video?keyword=diffsinger&order=click) created by Bilibili creators are released. And Diffsinger is introduced by [a very popular video](https://www.bilibili.com/video/BV1uM411t7ZJ) [![bilibili](https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1uM411t7ZJ)](https://www.bilibili.com/video/BV1uM411t7ZJ/)!
- This work is included by many famous speech/music synthesis open-source projects, such as [ESPNet ![](https://img.shields.io/github/stars/espnet/espnet?style=social)](https://github.com/espnet/espnet), [PaddlePaddle/Parakeet ![](https://img.shields.io/github/stars/PaddlePaddle/PaddleSpeech?style=social)](https://github.com/PaddlePaddle/PaddleSpeech), [muzic ![](https://img.shields.io/github/stars/microsoft/muzic?style=social)](https://github.com/microsoft/muzic).
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS</div><img src='images/portaspeech.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[PortaSpeech: Portable and High-Quality Generative Text-to-Speech](https://arxiv.org/abs/2109.15166) \\
Yi Ren\*, **Jinglin Liu**\*, Zhou Zhao

[**Project**](https://portaspeech.github.io/) \| [![](https://img.shields.io/github/stars/NATSpeech/NATSpeech?style=social&label=Code+Stars)](https://github.com/NATSpeech/NATSpeech) \| [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Demo)](https://huggingface.co/spaces/NATSpeech/PortaSpeech)


- The source codes of this paper are released together with the codes of DiffSpeech. This repository has received ![Github Stars](https://img.shields.io/github/stars/NATSpeech/NATSpeech?style=social); It is shown on the [Github Daily Trending List](https://github.motakasoft.com/trending/?d=2022-02-19&l=all).
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL</div><img src='images/neuralsvb.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Learning the Beauty in Songs: Neural Singing Voice Beautifier](https://arxiv.org/abs/2202.13277) \\
**Jinglin Liu**, Chengxi Li, Yi Ren, Zhiying Zhu, Zhou Zhao

[**Project**](https://neuralsvb.github.io/) \| [![](https://img.shields.io/github/stars/MoonInTheRiver/NeuralSVB?style=social&label=Stars)](https://github.com/MoonInTheRiver/NeuralSVB)  ![downloads](https://img.shields.io/github/downloads/MoonInTheRiver/NeuralSVB/total.svg)
</div>
</div>

## Recent Papers
- Ziyue Jiang\*, **Jinglin Liu**\*, Yi Ren\*, Jinzheng He\*, Chen Zhang, Zhenhui Ye, Pengfei Wei, Chunfeng Wang, Xiang Yin, Zejun Ma, Zhou Zhao, [Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis](https://openreview.net/forum?id=mvMI3N4AvD), **ICLR 2024** (\* equal contributions)
- **Jinglin Liu**\*, Zhenhui Ye\*, Qian Chen, Siqi Zheng, Wen Wang, Qinglin Zhang, Zhou Zhao, [DopplerBAS: Binaural Audio Synthesis Addressing Doppler Effect](https://aclanthology.org/2023.findings-acl.753/), **ACL 2023**. (\* equal contributions)
- Jinzheng He, **Jinglin Liu**, Zhenhui Ye, Rongjie Huang, Chenye Cui, Huadai Liu, Zhou Zhao, [RMSSinger: Realistic-Music-Score based Singing Voice Synthesis](https://arxiv.org/abs/2305.10686), **ACL 2023**
- Rongjie Huang, Jiawei Huang, Dongchao Yang, Yi Ren, Luping Liu, Mingze Li, Zhenhui Ye, **Jinglin Liu**, Xiang Yin, Zhou Zhao, [Make-An-Audio: Text-To-Audio Generation with Prompt-Enhanced Diffusion Models](https://arxiv.org/abs/2301.12661), **ICML 2023**
- Rongjie Huang\*, **Jinglin Liu**\*, Huadai Liu\*, Yi Ren, Lichao Zhang, Jinzheng He, Zhou Zhao, [TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation](https://openreview.net/forum?id=UVAmFAtC5ye), **ICLR 2023**. (\* equal contributions)
- Zhenhui Ye, Ziyue Jiang, Yi Ren, **Jinglin Liu**, Jinzheng He, Zhou Zhao, [GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis](https://openreview.net/forum?id=YfwMIDhPccD), **ICLR 2023**
- Ziyue Jiang, Zhe Su, Zhou Zhao, Qian Yang, Yi Ren, **Jinglin Liu**, Zhenhui Ye, [Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech](), **NeurIPS 2022**
- Rongjie Huang, Yi Ren, **Jinglin Liu**, Chenye Cui, Zhou Zhao, [GenerSpeech: Towards Style Transfer for Generalizable Out-Of-Domain Text-to-Speech](https://arxiv.org/abs/2205.07211), **NeurIPS 2022**
- **Jinglin Liu**, Chengxi Li, Yi Ren, Zhiying Zhu, Zhou Zhao, [Learning the Beauty in Songs: Neural Singing Voice Beautifier](https://arxiv.org/abs/2202.13277), **ACL 2022**
- **Jinglin Liu**\*, Chengxi Li\*, Yi Ren\*, Feiyang Chen, Zhou Zhao, [DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism](https://arxiv.org/abs/2105.02446), **AAAI 2022**. (\* equal contributions)
- Yi Ren\*, **Jinglin Liu**\*, Zhou Zhao, [PortaSpeech: Portable and High-Quality Generative Text-to-Speech](https://arxiv.org/abs/2109.15166), **NeurIPS 2021**. (\* equal contributions)
- **Jinglin Liu**, Zhiying Zhu, Yi Ren, Wencan Huang, Baoxing Huai, Nicholas Jing Yuan, Zhou Zhao, [Parallel and High-Fidelity Text-to-Lip Generation](https://arxiv.org/abs/2107.06831), **AAAI 2022**
- **Jinglin Liu**, Yi Ren, Zhou Zhao, Chen Zhang, Baoxing Huai, Jing Yuan, [FastLR: Non-Autoregressive Lipreading Model with Integrate-and-Fire](https://dl.acm.org/doi/10.1145/3394171.3413740), **ACM-MM 2020**
- **Jinglin Liu**, Yi Ren, Xu Tan, Chen Zhang, Tao Qin, Zhou Zhao and Tie-Yan Liu, [Task-Level Curriculum Learning for Non-Autoregressive Neural Machine Translation](https://www.ijcai.org/Proceedings/2020/0534.pdf), **IJCAI 2020**
- Yi Ren\*, **Jinglin Liu**\*, Xu Tan, Chen Zhang, Qin Tao, Zhou Zhao, Tie-Yan Liu, [SimulSpeech: End-to-End Simultaneous Speech to Text Translation](https://www.aclweb.org/anthology/2020.acl-main.350), **ACL 2020**. (\* equal contributions)
- Yi Ren\*, **Jinglin Liu**\*, Xu Tan, Zhou Zhao, Sheng Zhao, Tie-Yan Liu, [A Study of Non-autoregressive Model for Sequence Generation](https://arxiv.org/abs/2004.10454), **ACL 2020**. (\* equal contributions)

My full paper list is shown at [my scholar homepage](https://scholar.google.com/citations?user=Ri8x0jEAAAAJ).
