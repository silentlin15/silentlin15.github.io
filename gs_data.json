{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "Ri8x0jEAAAAJ", "source": "AUTHOR_PROFILE_PAGE", "name": "Jinglin Liu (刘静林)", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=Ri8x0jEAAAAJ&citpid=11", "affiliation": "Zhejiang University", "organization": 1118375729466322660, "interests": ["Speech", "Music", "Generative Models", "Translation", "Avatar"], "email_domain": "@zju.edu.cn", "homepage": "https://silentlin15.github.io/", "citedby": 2730, "publications": {"Ri8x0jEAAAAJ:9ZlFYXVOiuMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Make-an-audio: Text-to-audio generation with prompt-enhanced diffusion models", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:9ZlFYXVOiuMC", "num_citations": 408, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14204166098403262471", "cites_id": ["14204166098403262471"]}, "Ri8x0jEAAAAJ:TQgYirikUcIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Diffsinger: Singing voice synthesis via shallow diffusion mechanism", "pub_year": "2021"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:TQgYirikUcIC", "num_citations": 343, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10338801702241816573,17543750673797975335", "cites_id": ["10338801702241816573", "17543750673797975335"]}, "Ri8x0jEAAAAJ:ZeXyd9-uunAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Audiogpt: Understanding and generating speech, music, sound, and talking head", "pub_year": "2024"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:ZeXyd9-uunAC", "num_citations": 246, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10625702268349818855", "cites_id": ["10625702268349818855"]}, "Ri8x0jEAAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prodiff: Progressive fast diffusion model for high-quality text-to-speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:Zph67rFs4hoC", "num_citations": 211, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9223505264010200019", "cites_id": ["9223505264010200019"]}, "Ri8x0jEAAAAJ:mVmsd5A6BfQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:mVmsd5A6BfQC", "num_citations": 154, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16884839736713936995", "cites_id": ["16884839736713936995"]}, "Ri8x0jEAAAAJ:7PzlFSSx8tAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Generspeech: Towards style transfer for generalizable out-of-domain text-to-speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:7PzlFSSx8tAC", "num_citations": 115, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13191102001080802763", "cites_id": ["13191102001080802763"]}, "Ri8x0jEAAAAJ:LkGwnXOMwfcC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multi-Singer: Fast Multi-Singer Singing Voice Vocoder With A Large-Scale Corpus", "pub_year": "2021"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:LkGwnXOMwfcC", "num_citations": 115, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2358855456085494126", "cites_id": ["2358855456085494126"]}, "Ri8x0jEAAAAJ:hFOr9nPyWt4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "M4singer: A multi-style, multi-singer and musical score provided mandarin singing corpus", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:hFOr9nPyWt4C", "num_citations": 96, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1634477637622720706", "cites_id": ["1634477637622720706"]}, "Ri8x0jEAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "PortaSpeech: Portable and High-Quality Generative Text-to-Speech", "pub_year": "2021"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:eQOLeE2rZwMC", "num_citations": 91, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4177501522773357655", "cites_id": ["4177501522773357655"]}, "Ri8x0jEAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SimulSpeech: End-to-end simultaneous speech to text translation", "pub_year": "2020"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:2osOgNQ5qMEC", "num_citations": 87, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18282202564539184071", "cites_id": ["18282202564539184071"]}, "Ri8x0jEAAAAJ:maZDTaKrznsC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Mega-TTS 2: Boosting Prompting Mechanisms for Zero-Shot Speech Synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:maZDTaKrznsC", "num_citations": 85, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5311787723872082481,16735322993503076322", "cites_id": ["5311787723872082481", "16735322993503076322"]}, "Ri8x0jEAAAAJ:r0BpntZqJG4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Make-an-audio 2: Temporal-enhanced text-to-audio generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:r0BpntZqJG4C", "num_citations": 83, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=13517159671265524532", "cites_id": ["13517159671265524532"]}, "Ri8x0jEAAAAJ:UeHWp8X0CEIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "A study of non-autoregressive model for sequence generation", "pub_year": "2020"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:UeHWp8X0CEIC", "num_citations": 79, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14794750858649896134", "cites_id": ["14794750858649896134"]}, "Ri8x0jEAAAAJ:4DMP91E08xMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Singgan: Generative adversarial network for high-fidelity singing voice generation", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:4DMP91E08xMC", "num_citations": 70, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1698516610881405813", "cites_id": ["1698516610881405813"]}, "Ri8x0jEAAAAJ:iH-uZ7U-co4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Real3d-portrait: One-shot realistic 3d talking portrait synthesis", "pub_year": "2024"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:iH-uZ7U-co4C", "num_citations": 56, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4610920972123504276", "cites_id": ["4610920972123504276"]}, "Ri8x0jEAAAAJ:ULOm3_A8WrAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:ULOm3_A8WrAC", "num_citations": 56, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15292967138191810315", "cites_id": ["15292967138191810315"]}, "Ri8x0jEAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Denoispeech: Denoising text to speech with frame-level noise modeling", "pub_year": "2021"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:Tyk-4Ss8FVUC", "num_citations": 53, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16819689550610351819", "cites_id": ["16819689550610351819"]}, "Ri8x0jEAAAAJ:e5wmG9Sq2KIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Geneface++: Generalized and stable real-time audio-driven 3d talking face generation", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:e5wmG9Sq2KIC", "num_citations": 47, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=408392048948677980", "cites_id": ["408392048948677980"]}, "Ri8x0jEAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SimulSLT: End-to-End Simultaneous Sign Language Translation", "pub_year": "2021"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:_FxGoFyzp5QC", "num_citations": 44, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=450441650254501388", "cites_id": ["450441650254501388"]}, "Ri8x0jEAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Task-Level Curriculum Learning for Non-Autoregressive Neural Machine Translation", "pub_year": "2020"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:d1gkVwhDpl0C", "num_citations": 42, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14167179461331368816", "cites_id": ["14167179461331368816"]}, "Ri8x0jEAAAAJ:YsMSGLbcyi4C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model", "pub_year": "2021"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:YsMSGLbcyi4C", "num_citations": 39, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15315350381922618364", "cites_id": ["15315350381922618364"]}, "Ri8x0jEAAAAJ:qUcmZB5y_30C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "RMSSinger: Realistic-Music-Score based Singing Voice Synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:qUcmZB5y_30C", "num_citations": 22, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10533965237930127174", "cites_id": ["10533965237930127174"]}, "Ri8x0jEAAAAJ:hC7cP41nSMkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "CLAPSpeech: Learning Prosody from Text Context with Contrastive Language-Audio Pre-training", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:hC7cP41nSMkC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11061604911451895335", "cites_id": ["11061604911451895335"]}, "Ri8x0jEAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Learning the Beauty in Songs: Neural Singing Voice Beautifier", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:0EnyYjriUFMC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17442799639671484493", "cites_id": ["17442799639671484493"]}, "Ri8x0jEAAAAJ:W7OEmFMy1HYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "SimulLR: Simultaneous Lip Reading Transducer with Attention-Guided Adaptive Memory", "pub_year": "2021"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:W7OEmFMy1HYC", "num_citations": 20, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5842205079677030903", "cites_id": ["5842205079677030903"]}, "Ri8x0jEAAAAJ:-f6ydRqryjwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AV-TranSpeech: Audio-Visual Robust Speech-to-Speech Translation", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:-f6ydRqryjwC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3031965472100444937", "cites_id": ["3031965472100444937"]}, "Ri8x0jEAAAAJ:MXK_kJrjxJIC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Flow-based Unconstrained Lip to Speech Generation", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:MXK_kJrjxJIC", "num_citations": 18, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12941442660143753050", "cites_id": ["12941442660143753050"]}, "Ri8x0jEAAAAJ:L8Ckcad2t8MC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "VarietySound: Timbre-Controllable Video to Sound Generation via Unsupervised Information Disentanglement", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:L8Ckcad2t8MC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2333085745106701374", "cites_id": ["2333085745106701374"]}, "Ri8x0jEAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "FastLR: Non-Autoregressive Lipreading Model with Integrate-and-Fire", "pub_year": "2020"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:qjMakFHDy7sC", "num_citations": 16, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9581806397991323587", "cites_id": ["9581806397991323587"]}, "Ri8x0jEAAAAJ:4JMBOYKVnBMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Fastdiff 2: Revisiting and incorporating gans and diffusion models in high-fidelity speech synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:4JMBOYKVnBMC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5865263432404926087", "cites_id": ["5865263432404926087"]}, "Ri8x0jEAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Parallel and High-Fidelity Text-to-Lip Generation", "pub_year": "2021"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:roLk4NBRz8UC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1241053409280770066,249661701422637323", "cites_id": ["1241053409280770066", "249661701422637323"]}, "Ri8x0jEAAAAJ:dhFuZR0502QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MUG: A General Meeting Understanding and Generation Benchmark", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:dhFuZR0502QC", "num_citations": 9, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8623239451833201904", "cites_id": ["8623239451833201904"]}, "Ri8x0jEAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "MR-SVS: Singing voice synthesis with multi-reference encoder", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:UebtZRa9Y70C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18139761552468282156", "cites_id": ["18139761552468282156"]}, "Ri8x0jEAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:kNdYIx-mwKoC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=18386504940057315518", "cites_id": ["18386504940057315518"]}, "Ri8x0jEAAAAJ:_Qo2XoVZTnwC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Ada-TTA: Towards Adaptive High-Quality Text-to-Talking Avatar Synthesis", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:_Qo2XoVZTnwC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=2525485338562235164", "cites_id": ["2525485338562235164"]}, "Ri8x0jEAAAAJ:IWHjjKOFINEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment", "pub_year": "2023"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:IWHjjKOFINEC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3124350401729850271", "cites_id": ["3124350401729850271"]}, "Ri8x0jEAAAAJ:aqlVkmm33-oC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "DopplerBAS: Binaural Audio Synthesis Addressing Doppler Effect", "pub_year": "2022"}, "filled": false, "author_pub_id": "Ri8x0jEAAAAJ:aqlVkmm33-oC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5474058151368655377", "cites_id": ["5474058151368655377"]}}, "citedby5y": 2727, "hindex": 22, "hindex5y": 22, "i10index": 31, "i10index5y": 31, "cites_per_year": {"2020": 13, "2021": 78, "2022": 168, "2023": 634, "2024": 1218, "2025": 609}, "updated": "2025-06-28 08:15:55.738621"}